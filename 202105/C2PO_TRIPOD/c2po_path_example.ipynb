{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd067dd6d96080d572be6c61ca4501bfb2fec113f1c194d3c8a779348282f43ddd2",
   "display_name": "Python 3.8.8 64-bit ('c2po': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import src.data.data as data\n",
    "import src.data.config as cfg\n",
    "import src.interactive.functions as interactive\n",
    "import src.models.utils as model_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Source - Forward -> <- Backward - Sink\n",
    "source=\"Gruber admits that they attempt to steal $640 million\"\n",
    "sink=\"Karl is gunned down by Powell\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Comet Model\n",
    "\n",
    "#Model Args\n",
    "device=0\n",
    "#Model weights available at\n",
    "#https://drive.google.com/open?id=1FccEsYPUHnjzmX-Y5vjCBeyRt1pLo8FB\n",
    "model_file=\"/home/tslab/lab/comet_pretrained_models/atomic_pretrained_model.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading data from: data/atomic/processed/generation/categories_oEffect#oReact#oWant#xAttr#xEffect#xIntent#xNeed#xReact#xWant-maxe1_17-maxe2_35-maxr_1.pickle\n",
      "52\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LMModel(\n",
       "  (transformer): TransformerModel(\n",
       "    (embed): Embedding(40542, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): Block(\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_1): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_1): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_1): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_1): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_1): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_1): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_1): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_1): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_1): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_1): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_1): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_1): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): LMHead(\n",
       "    (decoder): Linear(in_features=768, out_features=40542, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "#Load Model in interactive Mode\n",
    "opt, state_dict = interactive.load_model_file(model_file)\n",
    "data_loader, text_encoder = interactive.load_data(\"atomic\", opt)\n",
    "n_ctx = data_loader.max_event + data_loader.max_effect\n",
    "n_vocab = len(text_encoder.encoder) + n_ctx\n",
    "model = interactive.make_model(opt, n_vocab, n_ctx, state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prefixes used in 'expand' function\n",
    "prefixes = ['tries', 'starts', 'wants', 'begins', ]\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions taken from C2PO - https://github.com/rajammanabrolu/C2PO/blob/master/C2PO/scripts/text-gen/generate.py\n",
    "\n",
    "#Query Input with Comet model\n",
    "def query(input_event, category='xNeed', sampling_algorithm='beam-10 '):\n",
    "    sampler = interactive.set_sampler(opt, sampling_algorithm, data_loader)\n",
    "\n",
    "    outputs = interactive.get_atomic_sequence(input_event, model, sampler, data_loader, text_encoder, category)[category]\n",
    "    for k, v in outputs.items():\n",
    "        outputs[k] = v[::-1]\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert event inputs to torch tensors\n",
    "\n",
    "def set_atomic_inputs(input_event, output_event, category, data_loader, text_encoder):\n",
    "    in_prefix, _ = data.atomic_data.do_example(text_encoder, input_event, None, True, None)\n",
    "    # out_prefix, _ = data.atomic_data.do_example(text_encoder, output_event, None, True, None)\n",
    "\n",
    "    # XMB = torch.zeros(1, data_loader.max_event + 1 + len(out_prefix)).long().to(cfg.device)\n",
    "    XMB = torch.zeros(1, data_loader.max_event + 1).long().to(cfg.device)\n",
    "\n",
    "    XMB[:, :len(in_prefix)] = torch.LongTensor(in_prefix)\n",
    "    XMB[:, data_loader.max_event] = torch.LongTensor([text_encoder.encoder[\"<{}>\".format(category)]])\n",
    "    # XMB[:, data_loader.max_event + 1:] = torch.LongTensor(out_prefix)\n",
    "\n",
    "    batch = {}\n",
    "    batch[\"sequences\"] = XMB\n",
    "    batch[\"attention_mask\"] = data.atomic_data.make_attention_mask(XMB)\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Branching: forward, backward\n",
    "def expand(event,character, width=2, depth=2, direction='forward'):\n",
    "    #Relation to be used with comet\n",
    "    if direction == 'forward':\n",
    "        category = 'xWant'\n",
    "    elif direction == 'backward':\n",
    "        category = 'xNeed'\n",
    "\n",
    "    stack = [[event]]\n",
    "    done = set()\n",
    "\n",
    "    outputs = []\n",
    "\n",
    "    while len(stack) > 0:\n",
    "        curr = stack.pop(0)\n",
    "        if len(curr) != 1:\n",
    "            outputs.append(curr)\n",
    "\n",
    "        # don't repeat previous actions\n",
    "        # print(f\"Curr: {curr[-1]}, Character:{character.split()}\")\n",
    "        previous_action = curr[-1][len(character.split()) + 1:]\n",
    "        # print(\"Previous action:\",previous_action)\n",
    "        if previous_action in done:\n",
    "            continue\n",
    "        done.add(previous_action)\n",
    "\n",
    "        # get predictions with comet model\n",
    "        out = query(curr[-1][len(character.split()) + 1:], category=category)\n",
    "\n",
    "        reqs = out['beams'][:width]\n",
    "        reqs = [[character, random.choice(prefixes)] + r.split() for r in reqs]\n",
    "        # print(f\"reqs: {reqs}\")\n",
    "        \n",
    "        # add new beams\n",
    "        for r in reqs:\n",
    "            if len(r) <= 3 or len(curr) >= depth or len(r) > 12:\n",
    "                continue\n",
    "            # print(f\"Insert: \",curr + [\" \".join(r)])\n",
    "            stack.insert(0, curr + [\" \".join(r)])\n",
    "\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Input Event:   rl is gunned down by Powell\n",
      "Target Effect: xNeed\n",
      "\n",
      "Candidate Sequences:\n",
      "none\n",
      "to get into a car\n",
      "to have a gun\n",
      "to get into an accident\n",
      "to get in the car\n",
      "to be in the wrong place\n",
      "to be driving\n",
      "to be in a car\n",
      "to drive a car\n",
      "get into a car\n",
      "\n",
      "====================================================\n",
      "\n",
      "Input Event:   rl begins to drive a car\n",
      "Target Effect: xNeed\n",
      "\n",
      "Candidate Sequences:\n",
      "start the car\n",
      "to get in the car\n",
      "to start the car\n",
      "to get into the car\n",
      "to have a car\n",
      "to open the car door\n",
      "to get the keys\n",
      "to get a license\n",
      "to have a license\n",
      "sit in car\n",
      "\n",
      "====================================================\n",
      "\n",
      "Input Event:   rl begins get into a car\n",
      "Target Effect: xNeed\n",
      "\n",
      "Candidate Sequences:\n",
      "to open the car door\n",
      "to get in the car\n",
      "to open the door\n",
      "to get into the car\n",
      "to have a car\n",
      "open the car door\n",
      "to go to the car\n",
      "to open the car door .\n",
      "to open the car\n",
      "to put on his shoes\n",
      "\n",
      "====================================================\n",
      "\n",
      "Input Event:   uber admits that they attempt to steal $640 million\n",
      "Target Effect: xWant\n",
      "\n",
      "Candidate Sequences:\n",
      "to go to the bank\n",
      "to get the money back\n",
      "to spend the money\n",
      "to get the money\n",
      "to buy a bigger house\n",
      "to buy a new car\n",
      "to win the game\n",
      "to make a profit\n",
      "to get a job\n",
      "to buy something\n",
      "\n",
      "====================================================\n",
      "\n",
      "Input Event:   uber begins to get a job\n",
      "Target Effect: xWant\n",
      "\n",
      "Candidate Sequences:\n",
      "to apply for a job\n",
      "to apply for jobs\n",
      "to go to work\n",
      "apply for a job\n",
      "to start working\n",
      "to work hard\n",
      "to get paid\n",
      "to celebrate\n",
      "to make money\n",
      "apply for jobs\n",
      "\n",
      "====================================================\n",
      "\n",
      "Input Event:   uber wants to buy something\n",
      "Target Effect: xWant\n",
      "\n",
      "Candidate Sequences:\n",
      "to go to the store\n",
      "to buy something\n",
      "to buy it\n",
      "go to the store\n",
      "to go to the store .\n",
      "to go to a store\n",
      "to make a purchase\n",
      "to go shopping\n",
      "to save money\n",
      "to purchase something\n",
      "\n",
      "====================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "width=2\n",
    "depth=2\n",
    "#Backward Branching\n",
    "endings = expand(sink,\"Karl\",width=width, depth=depth, direction='backward')\n",
    "\n",
    "#Forward Branching\n",
    "beginnings = expand(source,\"Gruber\",width=width, depth=depth, direction='forward')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Path Probability\n",
    "def getProb(input_event, output_event, category='xNeed'):\n",
    "    batch = set_atomic_inputs(input_event, output_event, category, data_loader, text_encoder)\n",
    "\n",
    "    start_idx = data_loader.max_event + data.atomic_data.num_delimiter_tokens[\"category\"]\n",
    "\n",
    "    XMB = batch[\"sequences\"][:, :start_idx]\n",
    "    MMB = batch[\"attention_mask\"][:, :start_idx]\n",
    "\n",
    "    XMB = model_utils.prepare_position_embeddings(opt, data_loader.vocab_encoder, XMB.unsqueeze(-1))\n",
    "\n",
    "    beam_ll = 0\n",
    "    for w in output_event.split():\n",
    "        lm_probs = F.log_softmax(model(\n",
    "            XMB.unsqueeze(1), sequence_mask=MMB), dim=-1)\n",
    "        dist = lm_probs[:, -1, :].squeeze()\n",
    "\n",
    "        word = w + '</w>'\n",
    "        # import ipdb; ipdb.set_trace()\n",
    "        if word not in data_loader.vocab_encoder:\n",
    "            return -1000\n",
    "        else:\n",
    "            tok_ll = dist[data_loader.vocab_encoder[w + '</w>']]\n",
    "            next_tok = torch.tensor([[data_loader.vocab_encoder[w + '</w>']]], dtype=torch.long, device=MMB.device)\n",
    "\n",
    "        beam_ll += tok_ll\n",
    "        next_pos = XMB[:, -1:, 1] + 1\n",
    "\n",
    "        next_x = torch.cat((next_tok, next_pos), -1).unsqueeze(1)\n",
    "        XMB = torch.cat((XMB, next_x), 1)\n",
    "        MMB = torch.cat([MMB, torch.ones(XMB.size(0), 1, device=MMB.device)], 1)\n",
    "    return beam_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "b:['Gruber admits that they attempt to steal $640 million', 'Gruber begins to get a job']\n",
      "e:['Karl is gunned down by Powell', 'Karl begins to drive a car']\n",
      "b_action:to get a job\n",
      "e_action:to drive a car\n",
      "Fwd Prob:20.392353057861328 Bwd Prob:12.578056335449219\n",
      "\n",
      "b:['Gruber admits that they attempt to steal $640 million', 'Gruber begins to get a job']\n",
      "e:['Karl is gunned down by Powell', 'Karl begins get into a car']\n",
      "b_action:to get a job\n",
      "e_action:get into a car\n",
      "Fwd Prob:23.434112548828125 Bwd Prob:19.131315231323242\n",
      "\n",
      "b:['Gruber admits that they attempt to steal $640 million', 'Gruber wants to buy something']\n",
      "e:['Karl is gunned down by Powell', 'Karl begins to drive a car']\n",
      "b_action:to buy something\n",
      "e_action:to drive a car\n",
      "Fwd Prob:24.16367530822754 Bwd Prob:13.487824440002441\n",
      "\n",
      "b:['Gruber admits that they attempt to steal $640 million', 'Gruber wants to buy something']\n",
      "e:['Karl is gunned down by Powell', 'Karl begins get into a car']\n",
      "b_action:to buy something\n",
      "e_action:get into a car\n",
      "Fwd Prob:29.24226188659668 Bwd Prob:13.337363243103027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all=[]\n",
    "fronts=[]\n",
    "backs=[]\n",
    "#Subject character in source event\n",
    "b_character=\"Gruber\"\n",
    "#Subject character in sink event\n",
    "e_character=\"Karl\"\n",
    "\n",
    "#Check all path combinations\n",
    "for b in beginnings:\n",
    "    for e in endings:\n",
    "        b_action = ' '.join(b[-1].split()[len(b_character.split()) + 1:])\n",
    "        e_action = ' '.join(e[-1].split()[len(e_character.split()) + 1:])\n",
    "        print(f\"b:{b}\\ne:{e}\")\n",
    "        print(f\"b_action:{b_action}\\ne_action:{e_action}\")\n",
    "        forward_prob = getProb(b_action, e_action, category='xWant')\n",
    "        backward_prob = getProb(e_action, b_action, category='xNeed')\n",
    "\n",
    "        # normalize by probability of predicting \"to\"\n",
    "        forward_prob /= getProb(b[-1], 'to', category='xWant')\n",
    "        backward_prob /= getProb(e[-1], 'to', category='xNeed')\n",
    "        print(f\"Fwd Prob:{forward_prob} Bwd Prob:{backward_prob}\\n\")\n",
    "        all.append((forward_prob + backward_prob, b + e[::-1]))\n",
    "        fronts.append(forward_prob.detach().cpu().numpy())\n",
    "        backs.append(backward_prob.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}